# RAGシステム設計レビュー結果

## レビュー概要

| 項目 | 内容 |
|------|------|
| レビュー日 | 2026-01-22 |
| 参照資料 | LangChain・LangGraph実践入門（NotebookLM） |
| 対象ファイル | query-pipeline.md, indexing-pipeline.md, update-pipeline.md, operations.md, README.md |
| 総合評価 | **B+（運用可能だが改善余地あり）** |

---

## エグゼクティブサマリー

本設計は**運用に耐えうる成熟度**を持ちつつも、LangGraphのベストプラクティスとの乖離や、評価・監視設計の不足が見られる。特に以下の7点が高優先度の改善事項である。

### 高優先度指摘事項（7件）

| # | 指摘内容 | 対象 | 影響度 |
|---|---------|------|--------|
| 1 | LangGraphのステート定義が未設計 | query-pipeline.md | 高 |
| 2 | チェックポイント機能によるエラー回復が未設計 | 全体 | 高 |
| 3 | ストリーミング出力の設計が欠落 | query-pipeline.md | 高 |
| 4 | Semantic Cacheの無効化戦略が未定義 | query-pipeline.md | 高 |
| 5 | RAGAS指標が運用メトリクスに統合されていない | operations.md | 高 |
| 6 | オンライン評価（LLMによる自動評価）の設計がない | operations.md | 高 |
| 7 | Rerankerが「TBD」のまま | README.md | 高 |

---

## 詳細レビュー結果

---

## 1. query-pipeline.md のレビュー

### 1.1 LangGraphパターンとの整合性

#### 指摘1（高優先度）: ステート定義が未設計

**現状:**
設計書ではパイプラインの処理フローは詳細に記載されているが、LangGraphで必須となる**ステート（State）の明示的なスキーマ定義**が存在しない。

**NotebookLMからの知識:**
> LangGraphでは、ステートのスキーマ定義にPython標準の TypedDict または Pydanticの BaseModel を使用できます。Pydanticの BaseModel を継承したクラスとしてステートを定義することが推奨されます。

**改善提案:**
以下のステート定義を設計書に追加すべき。

```python
from typing import Annotated
import operator
from pydantic import BaseModel, Field

class QueryPipelineState(BaseModel):
    """検索パイプラインのステート定義"""

    # 入力
    query: str = Field(..., description="ユーザーからの質問")
    user_id: str = Field(default="", description="ユーザーID")

    # 検索結果（Reducerでリストに追加）
    documents: Annotated[list[dict], operator.add] = Field(
        default=[], description="検索で取得したドキュメント"
    )

    # 処理状態
    route: str = Field(default="", description="ルーティング結果: vector_search|web_search|direct_answer")
    reranked_documents: list[dict] = Field(default=[], description="Reranking後のドキュメント")
    parent_documents: list[dict] = Field(default=[], description="親ドキュメント")

    # 生成結果
    answer: str = Field(default="", description="生成された回答")
    sources: list[str] = Field(default=[], description="参照元URL/パス")

    # 品質チェック
    context_relevant: bool = Field(default=False, description="コンテキスト評価結果")
    hallucination_detected: bool = Field(default=False, description="ハルシネーション検出結果")
    answer_useful: bool = Field(default=False, description="回答評価結果")

    # リトライ制御
    context_retry_count: int = Field(default=0, description="コンテキスト評価リトライ回数")
    hallucination_retry_count: int = Field(default=0, description="ハルシネーション検査リトライ回数")
    answer_retry_count: int = Field(default=0, description="回答評価リトライ回数")

    # キャッシュ
    cache_hit: bool = Field(default=False, description="Semantic Cacheヒット")

    # メタデータ
    request_id: str = Field(default="", description="リクエストID（トレーシング用）")
```

---

#### 指摘2（高優先度）: チェックポイント機能が未設計

**現状:**
エラーハンドリングの設計は充実しているが、LangGraphの**チェックポイント機能**を活用したエラー回復・再開の設計がない。

**NotebookLMからの知識:**
> グラフのコンパイル時にcheckpointer（MemorySaver、SqliteSaver、PostgresSaver など）を指定することで、各ステップごとにステートのスナップショットを保存します。処理中にエラーが発生したり、予期せぬ中断が起きたりした場合、直前のチェックポイントから同じステートで処理を再開できます。

**改善提案:**
以下のセクションを追加すべき。

```markdown
### チェックポイント設計

#### 目的
- エラー発生時の途中再開
- Human-in-the-loop対応（人間承認が必要な場合の一時停止）
- デバッグ・監査のためのステート履歴保存

#### 実装方針
- Checkpointer: PostgresSaver（本番環境）/ MemorySaver（開発環境）
- 保存タイミング: 各ノード実行後
- 保持期間: 7日間（設定可能）

#### 回復フロー
| エラー種別 | 回復方法 |
|-----------|---------|
| LLM APIタイムアウト | 直前のチェックポイントから自動再開 |
| ベクトルDB障害 | 障害復旧後に手動再開 |
| 人間介入要求 | 承認後にチェックポイントから継続 |
```

---

#### 指摘3（高優先度）: ストリーミング出力が未設計

**現状:**
回答生成後の出力設計はあるが、**ストリーミング出力（逐次表示）** の設計がない。

**NotebookLMからの知識:**
> LangGraphで構築したグラフを実行する際、streamメソッドを使用します。引数stream_modeによって出力内容を制御できます。
> - stream_mode="values": ステート全体の値をストリーミング
> - stream_mode="updates": 直前のステップで更新されたノードの情報だけを取得

**改善提案:**
以下のセクションを追加すべき。

```markdown
### ストリーミング出力設計

#### 目的
- ユーザー体験（UX）の向上
- 長時間レスポンス時の「処理中」表示
- トークン単位での逐次表示

#### 実装方針
- stream_mode: "updates"（回答生成ノードの出力のみ）
- 対象ノード: Generator（回答生成）
- 非対象: 検索、Reranking等の中間処理

#### フロントエンド連携
- Server-Sent Events (SSE) または WebSocket
- トークン単位でのチャンク送信
```

---

#### 指摘4（高優先度）: Semantic Cacheの無効化戦略が未定義

**現状:**
Semantic Cacheの導入は設計されているが、**ドキュメント更新時のキャッシュ無効化戦略**が定義されていない。古いキャッシュが返されるリスクがある。

**NotebookLMからの知識:**
> Semantic Cache（意味的キャッシュ）: 従来の完全一致によるキャッシュとは異なり、質問の「意味（ベクトル）」が近い場合にキャッシュを返す仕組みです。GPTCacheというOSSの活用が紹介されています。

**改善提案:**
以下のセクションを追加すべき。

```markdown
### Semantic Cache 無効化戦略

#### 無効化トリガー
| トリガー | 無効化範囲 | 方法 |
|---------|-----------|------|
| ドキュメント更新 | 関連キャッシュ | doc_idに紐づくキャッシュをパージ |
| インデックス再構築 | 全キャッシュ | 全件パージ |
| 埋め込みモデル変更 | 全キャッシュ | 全件パージ |

#### TTL設定
- デフォルトTTL: 24時間
- 高頻度更新ドキュメント: 1時間
- 静的コンテンツ: 7日間

#### 実装方針
- 更新パイプライン完了時にキャッシュ無効化APIを呼び出し
- doc_id → キャッシュキーのマッピングテーブルを維持
```

---

### 1.2 検索設計

#### 指摘5（中優先度）: RRFの実装詳細が不足

**現状:**
RRF（Reciprocal Rank Fusion）による結果統合は言及されているが、**パラメータや計算式**が明示されていない。

**改善提案:**
以下を追記すべき。

```markdown
### RRFの計算式

RRF_score(d) = Σ 1 / (k + rank_i(d))

- k: 定数（推奨値: 60）
- rank_i(d): i番目の検索手法におけるドキュメントdの順位

#### 重み付け
| 検索手法 | 重み | 理由 |
|---------|------|------|
| ベクトル検索 | 0.6 | 意味的類似性を重視 |
| BM25 | 0.4 | キーワード一致を補完 |
```

---

#### 指摘6（中優先度）: HyDEの適用条件が不明確

**現状:**
HyDEの説明はあるが、**いつ適用するか**の条件が明確でない。

**改善提案:**
以下を追記すべき。

```markdown
### HyDE適用条件

| 条件 | HyDE適用 | 理由 |
|------|---------|------|
| クエリが10トークン未満 | Yes | 情報量が少ないため拡張が有効 |
| クエリに専門用語が含まれる | Yes | 語彙のギャップを埋める |
| 単純なFAQ質問 | No | 直接検索で十分 |
| リアルタイム性が重要 | No | レイテンシ増加を避ける |

#### パフォーマンス影響
- 追加レイテンシ: 500ms〜1秒（LLM呼び出し1回分）
- 精度向上: 約10-20%（ドメインによる）
```

---

### 1.3 自己修正パターン

#### 評価: 良好

**現状の評価:**
Self-RAG/CRAG相当の自己修正ループが適切に設計されている。

- コンテキスト評価 → クエリ書き換え（リトライ上限3回）
- ハルシネーション検査 → 回答再生成（リトライ上限2回）
- 回答評価 → クエリ書き換え（リトライ上限3回）

**NotebookLMからの知識との整合性:**
> ステート内にretry_count（再試行回数）フィールドを持たせ、最大試行回数に達した場合は、品質が不十分でも強制終了または人間の介入を仰ぐように条件付きエッジを設計することが重要です。

設計書のリトライ上限設計はベストプラクティスに準拠している。

---

### 1.4 ガードレール

#### 評価: 良好

**現状の評価:**
入力/出力ガードレールの設計が適切になされている。

- 入力ガードレール: プロンプトインジェクション検出（NeMo, Semantic Router, Presidio）
- 出力ガードレール: 機密情報除去、不適切回答フィルタリング

**改善提案（低優先度）:**
構造化出力による強制の設計を追加すると良い。

```markdown
### 構造化出力による回答フォーマット強制

Pydanticモデルで回答フォーマットを定義し、不正な形式の出力を防止。

class AnswerOutput(BaseModel):
    answer: str = Field(..., description="回答本文")
    sources: list[str] = Field(..., description="参照元")
    confidence: float = Field(..., ge=0, le=1, description="信頼度スコア")
```

---

### 1.5 フィードバック設計

#### 評価: 優秀

**現状の評価:**
2層フィードバック管理（チャンク単位 + ドキュメント単位）の設計は**非常に優れている**。

- chunk_hashによる継承ロジック
- ドキュメント単位フォールバック（×0.5）
- Rerankingスコア調整（±10%）

この設計はDelete-then-Insert更新時のフィードバック喪失問題を解決している。

---

## 2. indexing-pipeline.md のレビュー

### 2.1 チャンク分割設計

#### 指摘7（中優先度）: オーバーラップの推奨値が未定義

**現状:**
「オーバーラップによる文脈分断対策」は言及されているが、**具体的な推奨値**が示されていない。

**改善提案:**
以下を追記すべき。

```markdown
### オーバーラップ設定

| チャンクサイズ | 推奨オーバーラップ | オーバーラップ率 |
|--------------|-------------------|-----------------|
| 500トークン | 50-100トークン | 10-20% |
| 1000トークン | 100-200トークン | 10-20% |
| 2000トークン | 200-400トークン | 10-20% |

#### 注意点
- オーバーラップが大きすぎると重複検索が増加
- オーバーラップが小さすぎると文脈が分断
- 推奨: 10-20%のオーバーラップ率
```

---

#### 指摘8（中優先度）: セマンティックチャンキングの実装詳細が不足

**現状:**
セマンティックチャンキングの概念は説明されているが、**具体的な実装方針**（閾値設定等）が不足。

**改善提案:**
以下を追記すべき。

```markdown
### セマンティックチャンキング実装

#### アルゴリズム
1. 文単位でテキストを分割
2. 隣接文のEmbedding間のコサイン類似度を計算
3. 類似度が閾値（推奨: 0.5）を下回る箇所で分割
4. 分割後のチャンクが最小サイズ（推奨: 100トークン）未満の場合は結合

#### パラメータ
| パラメータ | 推奨値 | 説明 |
|-----------|--------|------|
| 類似度閾値 | 0.5 | これより低い箇所で分割 |
| 最小チャンクサイズ | 100トークン | これより小さいチャンクは結合 |
| 最大チャンクサイズ | 1000トークン | これより大きい場合は強制分割 |
```

---

### 2.2 埋め込み設計

#### 評価: 良好

**現状の評価:**
- ruri-v3-310m（日本語特化、JMTEBでSOTA）の選定は適切
- Fine-tuning検討の言及あり
- マルチモーダル埋め込みの考慮あり

---

### 2.3 インデックス設計

#### 指摘9（低優先度）: chunk_hash生成アルゴリズムが未定義

**現状:**
chunk_hashの重要性は説明されているが、**生成アルゴリズム**が明示されていない。

**改善提案:**
以下を追記すべき。

```markdown
### chunk_hash生成

#### アルゴリズム
- ハッシュ関数: SHA-256
- 入力: チャンクテキスト（正規化済み）
- 正規化: 空白統一、改行削除、小文字化

#### コード例
import hashlib

def generate_chunk_hash(text: str) -> str:
    normalized = " ".join(text.lower().split())
    return hashlib.sha256(normalized.encode()).hexdigest()[:16]
```

---

## 3. update-pipeline.md のレビュー

### 3.1 更新戦略

#### 評価: 優秀

**現状の評価:**
3つの更新戦略（immediate/batch/full_rebuild）と3点セット差分管理（doc_id, chunk_id, chunk_hash）の設計は適切。

---

### 3.2 整合性管理

#### 評価: 良好

**現状の評価:**
- Delete-then-Insertのトランザクション的一貫性
- アトミック切り替え（エイリアス方式）
- 論理削除（is_active=false）

設計は妥当だが、以下の追記を推奨。

#### 指摘10（低優先度）: トランザクション実装の詳細不足

**改善提案:**

```markdown
### トランザクション実装

#### Qdrantでの実装
Qdrantはトランザクションをネイティブサポートしないため、以下の方式で疑似的に実現。

1. 新チャンクを別コレクションに書き込み
2. 書き込み完了を確認
3. エイリアスを新コレクションに切り替え（アトミック）
4. 旧コレクションを削除

#### エラー時のロールバック
- 書き込み失敗: 新コレクションを破棄
- エイリアス切り替え失敗: 旧コレクションのまま継続
```

---

### 3.3 フィードバック継承

#### 評価: 優秀

2層フィードバック管理とchunk_hashによる継承ロジックは**優れた設計**。

---

## 4. operations.md のレビュー

### 4.1 メトリクス設計

#### 指摘11（高優先度）: RAGAS指標が運用メトリクスに統合されていない

**現状:**
運用メトリクスにRAGASの4指標が含まれていない。「回答品質スコア（RAGAS平均）」は日次レポートに記載があるが、**リアルタイム監視対象になっていない**。

**NotebookLMからの知識:**
> RAGAS（RAG Assessment）は、RAGパイプラインの性能を測るためのフレームワークです。
> - Context precision（コンテキストの適合率）
> - Context recall（コンテキストの再現率）
> - Faithfulness（忠実性）- ハルシネーションの有無
> - Answer relevancy（回答の関連性）

**改善提案:**
以下のメトリクスを追加すべき。

```markdown
### RAG品質メトリクス（リアルタイム）

| メトリクス | 説明 | 警告閾値 | 危険閾値 |
|-----------|------|---------|---------|
| Faithfulness（忠実性） | 回答がコンテキストに基づいているか | < 0.8 | < 0.6 |
| Answer relevancy（関連性） | 回答が質問に適切か | < 0.8 | < 0.6 |
| Context precision（適合率） | 検索結果の有用性 | < 0.7 | < 0.5 |
| Context recall（再現率） | 必要情報の網羅性 | < 0.7 | < 0.5 |

#### 計測方法
- サンプリング: 全リクエストの10%を自動評価
- 評価モデル: GPT-4o-mini（コスト効率）
- 集計間隔: 1時間ごと
```

---

#### 指摘12（中優先度）: 検索品質メトリクスの欠落

**現状:**
検索品質を測るMRR（Mean Reciprocal Rank）やRecall@kが定義されていない。

**改善提案:**
以下を追加すべき。

```markdown
### 検索品質メトリクス

| メトリクス | 説明 | 目標値 |
|-----------|------|--------|
| MRR（平均逆順位） | 正解が何位に出現するかの平均 | > 0.7 |
| Recall@5 | 上位5件に正解が含まれる割合 | > 0.9 |
| Recall@10 | 上位10件に正解が含まれる割合 | > 0.95 |
```

---

### 4.2 オンライン評価

#### 指摘13（高優先度）: オンライン評価の設計がない

**現状:**
オフライン評価（RAGAS）の言及はあるが、**本番稼働中のオンライン評価**の設計がない。

**NotebookLMからの知識:**
> オンライン評価（Online Evaluation）:
> - タイミング: 本番システムへの反映後（運用段階）
> - 方法: 実際のユーザーのトラフィック（ログ）を使用。ユーザーからのフィードバック（Good/Bad）や、実行ログに対して別のLLMが自動評価を行う「Online Evaluator」を利用します。

**改善提案:**
以下のセクションを追加すべき。

```markdown
### オンライン評価設計

#### 目的
- 本番環境での回答品質の継続的監視
- 未知の質問パターンへの対応状況把握
- フィードバックデータの自動収集

#### 実装方針
1. **サンプリング評価**
   - 全リクエストの10%を自動評価対象に
   - 評価モデル: GPT-4o-mini（低コスト）
   - 評価観点: Faithfulness, Answer relevancy

2. **ユーザーフィードバック**
   - Good/Badボタンの設置
   - フィードバック率の目標: 5%以上

3. **評価結果の活用**
   - 低スコア回答のアノテーションキュー追加
   - 高スコア回答のテストデータセット追加

#### Automation Rule（自動化ルール）
| 条件 | アクション |
|------|-----------|
| Good評価 | テストデータセットに追加、Few-shot例として保存 |
| Bad評価 | アノテーションキューに追加、開発者レビュー |
| Faithfulness < 0.5 | アラート発報、手動確認 |
```

---

### 4.3 合成テストデータ

#### 指摘14（中優先度）: 合成テストデータ生成の設計がない

**現状:**
評価用データセットの言及はあるが、**合成テストデータ生成**の設計がない。

**改善提案:**
以下を追加すべき。

```markdown
### 合成テストデータ生成

#### 目的
- オフライン評価用の質問-回答ペアを自動生成
- 新規ドキュメント追加時のテストケース拡充

#### 実装方針（RAGASのTestsetGenerator）
1. ドキュメントからLLMで質問を自動生成
2. Ground Truth（期待回答）を同時に生成
3. 難易度別に分類（Simple, Reasoning, Multi-context）

#### 生成規模
- 初期: 500件
- 増分: ドキュメント更新ごとに50件追加
```

---

### 4.4 ログ設計

#### 評価: 良好

必須ログフィールドの設計は適切。request_idによるトレーシング対応あり。

#### 指摘15（低優先度）: Langfuse統合の詳細が不足

**改善提案:**
以下を追記すべき。

```markdown
### Langfuse統合

#### トレースの構成
- Trace: 1リクエスト = 1トレース
- Span: 各ノード（検索、生成等）= 1スパン
- Generation: LLM呼び出し = 1ジェネレーション

#### 記録項目
- 入力トークン数、出力トークン数
- モデル名、プロンプトテンプレート
- レイテンシ（ノード単位）
- コスト（LLM APIコスト）
```

---

## 5. README.md のレビュー

### 5.1 SLA/SLO

#### 評価: 良好

現実的な目標値設定がされている。

- 月間稼働率: 99.5%
- P50レイテンシ: 2秒以内
- P95レイテンシ: 5秒以内
- エラー率: 月間0.5%以内

---

### 5.2 技術スタック

#### 指摘16（高優先度）: Rerankerが「TBD」のまま

**現状:**
Rerankerが「TBD」のまま放置されており、検索品質に直結する重要コンポーネントが未決定。

**改善提案:**
以下の選定基準と候補を追記すべき。

```markdown
### Reranker選定

#### 候補モデル

| モデル | 特徴 | レイテンシ | コスト |
|--------|------|-----------|--------|
| Cohere Rerank v3 | 高精度、API提供 | 100-200ms | $1/1000クエリ |
| bge-reranker-v2-m3 | オープンソース、多言語対応 | 50-100ms | 自前ホスト |
| Japanese Reranker | 日本語特化 | 50-100ms | 自前ホスト |

#### 選定基準
1. 日本語対応の品質
2. レイテンシ（100ms以内が望ましい）
3. コスト（APIか自前ホストか）
4. 運用負荷

#### 推奨
- 初期フェーズ: Cohere Rerank v3（API、運用負荷低）
- スケール後: bge-reranker-v2-m3（自前ホスト、コスト最適化）
```

---

#### 指摘17（中優先度）: 埋め込みモデル移行計画がない

**現状:**
埋め込みモデル変更時の移行計画が存在しない。

**改善提案:**
以下を追記すべき。

```markdown
### 埋め込みモデル移行計画

#### 移行が必要なケース
- より高精度なモデルのリリース
- コスト最適化
- ライセンス変更

#### 移行手順
1. 新モデルで全ドキュメントを再埋め込み（バックグラウンド）
2. 新インデックスを別名で作成
3. A/Bテストで品質比較
4. エイリアス切り替えで本番反映
5. 旧インデックスを一定期間保持後削除

#### 推定コスト（100万チャンク）
- 再埋め込み処理時間: 約4時間（GPU使用時）
- ストレージ増加: 一時的に2倍
```

---

## 指摘事項サマリー

### 高優先度（7件）

| # | 指摘内容 | 対象ファイル | 改善提案 |
|---|---------|-------------|---------|
| 1 | ステート定義が未設計 | query-pipeline.md | Pydanticでステートスキーマを定義 |
| 2 | チェックポイント機能が未設計 | 全体 | PostgresSaverによる永続化設計を追加 |
| 3 | ストリーミング出力が未設計 | query-pipeline.md | stream_mode設計を追加 |
| 4 | Semantic Cache無効化戦略が未定義 | query-pipeline.md | TTL・パージ戦略を追加 |
| 5 | RAGAS指標が運用メトリクスに未統合 | operations.md | 4指標をリアルタイム監視に追加 |
| 6 | オンライン評価の設計がない | operations.md | LLMによる自動評価設計を追加 |
| 7 | Rerankerが「TBD」のまま | README.md | 選定基準と候補を明示 |

### 中優先度（6件）

| # | 指摘内容 | 対象ファイル |
|---|---------|-------------|
| 8 | RRFの実装詳細が不足 | query-pipeline.md |
| 9 | HyDEの適用条件が不明確 | query-pipeline.md |
| 10 | オーバーラップの推奨値が未定義 | indexing-pipeline.md |
| 11 | セマンティックチャンキングの実装詳細が不足 | indexing-pipeline.md |
| 12 | 検索品質メトリクス（MRR, Recall@k）の欠落 | operations.md |
| 13 | 合成テストデータ生成の設計がない | operations.md |

### 低優先度（4件）

| # | 指摘内容 | 対象ファイル |
|---|---------|-------------|
| 14 | 構造化出力による回答フォーマット強制 | query-pipeline.md |
| 15 | chunk_hash生成アルゴリズムが未定義 | indexing-pipeline.md |
| 16 | トランザクション実装の詳細不足 | update-pipeline.md |
| 17 | Langfuse統合の詳細が不足 | operations.md |

---

## 良好な設計ポイント

本設計で特に優れている点を記載する。

1. **2層フィードバック管理** - チャンク単位とドキュメント単位の両方でフィードバックを管理し、Delete-then-Insert更新時のデータ喪失を防止している
2. **自己修正ループ** - Self-RAG/CRAG相当の設計が適切に実装されており、リトライ上限も設定されている
3. **ホット/コールドインデックス分離** - 更新頻度に応じたインデックス設計が実用的
4. **ガードレール設計** - 入力/出力両方のガードレールが具体的に設計されている
5. **SLA/SLO設計** - 現実的な目標値が設定されている
6. **エラーハンドリング** - 各ノードのエラー種別と対処方針が網羅的

---

## 次のアクション

1. **高優先度指摘の対応**（推奨: 実装前に完了）
   - ステート定義の追加
   - チェックポイント設計の追加
   - ストリーミング出力設計の追加
   - Semantic Cache無効化戦略の追加
   - RAGAS指標の運用メトリクス統合
   - オンライン評価設計の追加
   - Reranker選定の完了

2. **中優先度指摘の対応**（推奨: 実装中に対応）
   - RRF詳細、HyDE適用条件の追記
   - オーバーラップ推奨値の追記
   - 検索品質メトリクスの追加

3. **レビュー後の検証**
   - 修正後の設計書を再レビュー
   - 実装時にベストプラクティスとの整合性を確認
